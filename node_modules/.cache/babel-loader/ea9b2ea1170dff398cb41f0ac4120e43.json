{"ast":null,"code":"import _slicedToArray from \"C:/Users/R/Desktop/DialogueSystems/SwedishApp/node_modules/babel-preset-react-app/node_modules/@babel/runtime/helpers/esm/slicedToArray\";\nimport _objectSpread from \"C:/Users/R/Desktop/DialogueSystems/SwedishApp/node_modules/babel-preset-react-app/node_modules/@babel/runtime/helpers/esm/objectSpread2\";\n\nvar _jsxFileName = \"C:\\\\Users\\\\R\\\\Desktop\\\\DialogueSystems\\\\SwedishApp\\\\src\\\\index.tsx\",\n    _s = $RefreshSig$();\n\nimport \"./styles.scss\";\nimport * as React from \"react\";\nimport { useEffect } from 'react';\nimport * as ReactDOM from \"react-dom\";\nimport { Machine, assign, send } from \"xstate\";\nimport { useMachine, asEffect } from \"@xstate/react\";\nimport { inspect } from \"@xstate/inspect\";\nimport { dmMachine } from \"./dmAppointmentLab4\";\ninspect({\n  url: \"https://statecharts.io/inspect\",\n  iframe: false\n});\nimport { useSpeechSynthesis } from 'react-speech-kit';\nimport SpeechRecognition, { useSpeechRecognition } from 'react-speech-recognition';\nimport { jsxDEV as _jsxDEV } from \"react/jsx-dev-runtime\";\nconst machine = Machine({\n  id: 'root',\n  type: 'parallel',\n  states: {\n    dm: _objectSpread({}, dmMachine),\n    asrtts: {\n      initial: 'idle',\n      states: {\n        idle: {\n          on: {\n            LISTEN: 'recognising',\n            SPEAK: {\n              target: 'speaking',\n              actions: assign((_context, event) => {\n                return {\n                  ttsAgenda: event.value\n                };\n              })\n            }\n          }\n        },\n        recognising: {\n          initial: 'progress',\n          entry: 'recStart',\n          exit: 'recStop',\n          on: {\n            ASRRESULT: {\n              actions: ['recLogResult', assign((_context, event) => {\n                return {\n                  recResult: event.value\n                };\n              })],\n              target: '.match'\n            },\n            RECOGNISED: 'idle',\n            TIMEOUT1: 'idle',\n            TIMEOUT2: 'idle',\n            TIMEOUT3: 'idle',\n            TIMEOUT4: 'idle'\n          },\n          states: {\n            progress: {},\n            match: {\n              entry: send('RECOGNISED')\n            }\n          }\n        },\n        speaking: {\n          entry: 'ttsStart',\n          on: {\n            ENDSPEECH: 'idle'\n          }\n        }\n      }\n    }\n  }\n}, {\n  actions: {\n    recLogResult: context => {\n      /* context.recResult = event.recResult; */\n      console.log('<< ASR: ' + context.recResult);\n    },\n    test: () => {\n      console.log('test');\n    },\n    logIntent: context => {\n      /* context.nluData = event.data */\n      console.log('<< NLU intent: ' + context.nluData.intent.name);\n    }\n  }\n});\n\nconst ReactiveButton = props => {\n  switch (true) {\n    case props.state.matches({\n      asrtts: 'recognising'\n    }):\n      return /*#__PURE__*/_jsxDEV(\"div\", {\n        children: [\"                \", /*#__PURE__*/_jsxDEV(\"button\", _objectSpread(_objectSpread({\n          type: \"button\",\n          className: \"glow-on-hover\",\n          style: {\n            animation: \"glowing 20s linear\"\n          }\n        }, props), {}, {\n          children: \"Listening...\"\n        }), void 0, false, {\n          fileName: _jsxFileName,\n          lineNumber: 98,\n          columnNumber: 38\n        }, this), /*#__PURE__*/_jsxDEV(\"p\", {\n          style: {\n            color: \"yellow\"\n          },\n          children: \"aldskhg;lsag;lksadf;lksadlkfha\"\n        }, void 0, false, {\n          fileName: _jsxFileName,\n          lineNumber: 102,\n          columnNumber: 17\n        }, this), /*#__PURE__*/_jsxDEV(\"a\", {\n          href: \"\"\n        }, void 0, false, {\n          fileName: _jsxFileName,\n          lineNumber: 103,\n          columnNumber: 17\n        }, this)]\n      }, void 0, true, {\n        fileName: _jsxFileName,\n        lineNumber: 98,\n        columnNumber: 17\n      }, this);\n\n    case props.state.matches({\n      asrtts: 'speaking'\n    }):\n      return /*#__PURE__*/_jsxDEV(\"div\", {\n        className: \"style_of_new_element\",\n        children: /*#__PURE__*/_jsxDEV(\"button\", _objectSpread(_objectSpread({\n          type: \"button\",\n          className: \"glow-on-hover\",\n          style: {\n            animation: \"bordering 1s infinite\"\n          }\n        }, props), {}, {\n          children: \"Speaking...\"\n        }), void 0, false, {\n          fileName: _jsxFileName,\n          lineNumber: 111,\n          columnNumber: 17\n        }, this)\n      }, void 0, false, {\n        fileName: _jsxFileName,\n        lineNumber: 109,\n        columnNumber: 17\n      }, this);\n\n    default:\n      return /*#__PURE__*/_jsxDEV(\"button\", _objectSpread(_objectSpread({\n        type: \"button\",\n        className: \"glow-on-hover\"\n      }, props), {}, {\n        children: \"Click to start\"\n      }), void 0, false, {\n        fileName: _jsxFileName,\n        lineNumber: 119,\n        columnNumber: 17\n      }, this);\n  }\n};\n\n_c = ReactiveButton;\n\nfunction App() {\n  _s();\n\n  const _useSpeechSynthesis = useSpeechSynthesis({\n    onEnd: () => {\n      send('ENDSPEECH');\n    }\n  }),\n        speak = _useSpeechSynthesis.speak,\n        cancel = _useSpeechSynthesis.cancel,\n        speaking = _useSpeechSynthesis.speaking; // const { listen, listening, stop } = useSpeechRecognition({\n  //     onResult: (result: any) => {\n  //         send({ type: \"ASRRESULT\", value: result });\n  //     },\n  // });\n  // const [current, send, service] = useMachine(machine, {\n  //     devTools: true,\n  //     language: \"sv-SE\",\n  //     actions: {\n  //         recStart: asEffect(() => {\n  //             language: \"sv-SE\"\n  //             console.log(\"I'm listening.\");\n  //             listen({\n  //                 interimResults: false,\n  //                 continuous: true,\n  //                 language: \"sv-SE\"\n  //             });\n  //         }),\n  //         recStop: asEffect(() => {\n  //             console.log('Recognition stopped.');\n  //             stop()\n  //         }),\n  //         changeColour: asEffect((context) => {\n  //             console.log('Repainting...');\n  //             document.body.style.background = context.recResult;\n  //         }),\n  //         ttsStart: asEffect((context, effect) => {\n  //             console.log('Speaking...');\n  //             speak({ language: \"sv-SE\",\n  //                 text: context.ttsAgenda })\n  //         }),\n  //         ttsCancel: asEffect((context, effect) => {\n  //             console.log('TTS STOP...');\n  //             cancel()\n  //         })\n  //         /speak: asEffect((context) => {\n  //      * console.log('Speaking...');\n  //          *     speak({text: context.ttsAgenda })\n  //          * } \n  //     }\n  // });\n\n\n  const _useSpeechRecognition = useSpeechRecognition({}),\n        transcript = _useSpeechRecognition.transcript,\n        interimTranscript = _useSpeechRecognition.interimTranscript,\n        finalTranscript = _useSpeechRecognition.finalTranscript,\n        resetTranscript = _useSpeechRecognition.resetTranscript,\n        listening = _useSpeechRecognition.listening; // const listenContinuously = () => {\n  //     SpeechRecognition.startListening({\n  //       continuous: true,\n  //       language: 'en-GB',\n  //     });\n  //   };\n\n\n  useEffect(() => {\n    // const { transcript, resetTranscript } = useSpeechRecognition({});\n    SpeechRecognition.startListening({\n      continuous: false,\n      language: \"sv-SE\"\n    });\n    console.log('In startListening');\n\n    onResult: send({\n      type: \"ASRRESULT\",\n      value: finalTranscript\n    });\n\n    resetTranscript();\n  }, [interimTranscript, finalTranscript]);\n\n  const _useMachine = useMachine(machine, {\n    devTools: true,\n    language: \"sv-SE\",\n    actions: {\n      recStart: asEffect(() => {\n        language: \"sv-SE\"; //\n\n\n        console.log(\"I'm listening.\");\n      }),\n      recStop: asEffect(() => {\n        console.log('Recognition stopped.');\n        stop();\n      }),\n      changeColour: asEffect(context => {\n        console.log('Repainting...');\n        document.body.style.background = context.recResult;\n      }),\n      ttsStart: asEffect((context, effect) => {\n        console.log('Speaking...');\n        speak({\n          language: \"sv-SE\",\n          text: context.ttsAgenda\n        });\n      }),\n      ttsCancel: asEffect((context, effect) => {\n        console.log('TTS STOP...');\n        cancel();\n      })\n      /* speak: asEffect((context) => {\r\n      * console.log('Speaking...');\r\n       *     speak({text: context.ttsAgenda })\r\n       * } */\n\n    }\n  }),\n        _useMachine2 = _slicedToArray(_useMachine, 3),\n        current = _useMachine2[0],\n        send = _useMachine2[1],\n        service = _useMachine2[2];\n  /*\r\n      const { listen, listening, stop } = useSpeechRecognition({\r\n  \r\n          onResult: (result: any) => {\r\n              send({ type: \"ASRRESULT\", value: result });\r\n          },\r\n      });\r\n      const [current, send, service] = useMachine(machine, {\r\n          devTools: true,\r\n          language: \"sv-SE\",\r\n          actions: {\r\n              recStart: asEffect(() => {\r\n                  language: \"sv-SE\"\r\n                  console.log(\"I'm listening.\");\r\n                  listen({\r\n                      interimResults: false,\r\n                      continuous: true,\r\n                      language: \"sv-SE\"\r\n                  });\r\n              }),\r\n              recStop: asEffect(() => {\r\n                  console.log('Recognition stopped.');\r\n                  stop()\r\n              }),\r\n              changeColour: asEffect((context) => {\r\n                  console.log('Repainting...');\r\n                  document.body.style.background = context.recResult;\r\n              }),\r\n              ttsStart: asEffect((context, effect) => {\r\n                  console.log('Speaking...');\r\n                  speak({ language: \"sv-SE\",\r\n                      text: context.ttsAgenda })\r\n              }),\r\n              ttsCancel: asEffect((context, effect) => {\r\n                  console.log('TTS STOP...');\r\n                  cancel()\r\n              })\r\n              /speak: asEffect((context) => {\r\n  \t     * console.log('Speaking...');\r\n               *     speak({text: context.ttsAgenda })\r\n               * } \r\n          }\r\n      });\r\n  */\n\n\n  return /*#__PURE__*/_jsxDEV(\"div\", {\n    className: \"App\",\n    children: /*#__PURE__*/_jsxDEV(ReactiveButton, {\n      state: current,\n      onClick: () => send('CLICK')\n    }, void 0, false, {\n      fileName: _jsxFileName,\n      lineNumber: 275,\n      columnNumber: 13\n    }, this)\n  }, void 0, false, {\n    fileName: _jsxFileName,\n    lineNumber: 274,\n    columnNumber: 9\n  }, this);\n}\n\n_s(App, \"S0jl9nGThNG8GA3KhfsAMVycrzM=\", false, function () {\n  return [useSpeechSynthesis, useSpeechRecognition, useMachine];\n});\n\n_c2 = App;\n;\n/* RASA API\r\n *  */\n\nconst proxyurl = \"https://cors-anywhere.herokuapp.com/\";\nconst rasaurl = 'https://rafalappointment.herokuapp.com/model/parse';\n\nconst nluRequest = text => fetch(new Request(proxyurl + rasaurl, {\n  method: 'POST',\n  headers: {\n    'Origin': 'http://maraev.me'\n  },\n  // only required with proxy\n  body: \"{\\\"text\\\": \\\"\".concat(text, \"\\\"}\")\n})).then(data => data.json());\n\nconst rootElement = document.getElementById(\"root\");\nReactDOM.render( /*#__PURE__*/_jsxDEV(App, {}, void 0, false, {\n  fileName: _jsxFileName,\n  lineNumber: 296,\n  columnNumber: 5\n}, this), rootElement);\n\nvar _c, _c2;\n\n$RefreshReg$(_c, \"ReactiveButton\");\n$RefreshReg$(_c2, \"App\");","map":{"version":3,"sources":["C:/Users/R/Desktop/DialogueSystems/SwedishApp/src/index.tsx"],"names":["React","useEffect","ReactDOM","Machine","assign","send","useMachine","asEffect","inspect","dmMachine","url","iframe","useSpeechSynthesis","SpeechRecognition","useSpeechRecognition","machine","id","type","states","dm","asrtts","initial","idle","on","LISTEN","SPEAK","target","actions","_context","event","ttsAgenda","value","recognising","entry","exit","ASRRESULT","recResult","RECOGNISED","TIMEOUT1","TIMEOUT2","TIMEOUT3","TIMEOUT4","progress","match","speaking","ENDSPEECH","recLogResult","context","console","log","test","logIntent","nluData","intent","name","ReactiveButton","props","state","matches","animation","color","App","onEnd","speak","cancel","transcript","interimTranscript","finalTranscript","resetTranscript","listening","startListening","continuous","language","onResult","devTools","recStart","recStop","stop","changeColour","document","body","style","background","ttsStart","effect","text","ttsCancel","current","service","proxyurl","rasaurl","nluRequest","fetch","Request","method","headers","then","data","json","rootElement","getElementById","render"],"mappings":";;;;;;AAAA,OAAO,eAAP;AACA,OAAO,KAAKA,KAAZ,MAAuB,OAAvB;AACA,SAAQC,SAAR,QAAwB,OAAxB;AACA,OAAO,KAAKC,QAAZ,MAA0B,WAA1B;AACA,SAASC,OAAT,EAAkBC,MAAlB,EAA0BC,IAA1B,QAA6C,QAA7C;AAEA,SAASC,UAAT,EAAqBC,QAArB,QAAqC,eAArC;AACA,SAASC,OAAT,QAAwB,iBAAxB;AACA,SAASC,SAAT,QAA0B,qBAA1B;AAGAD,OAAO,CAAC;AACJE,EAAAA,GAAG,EAAE,gCADD;AAEJC,EAAAA,MAAM,EAAE;AAFJ,CAAD,CAAP;AAKA,SAASC,kBAAT,QAAmC,kBAAnC;AACA,OAAQC,iBAAR,IAA4BC,oBAA5B,QAAwD,0BAAxD;;AAGA,MAAMC,OAAO,GAAGZ,OAAO,CAA4B;AAC/Ca,EAAAA,EAAE,EAAE,MAD2C;AAE/CC,EAAAA,IAAI,EAAE,UAFyC;AAG/CC,EAAAA,MAAM,EAAE;AACJC,IAAAA,EAAE,oBACKV,SADL,CADE;AAIJW,IAAAA,MAAM,EAAE;AACJC,MAAAA,OAAO,EAAE,MADL;AAEJH,MAAAA,MAAM,EAAE;AACJI,QAAAA,IAAI,EAAE;AACFC,UAAAA,EAAE,EAAE;AACAC,YAAAA,MAAM,EAAE,aADR;AAEAC,YAAAA,KAAK,EAAE;AACHC,cAAAA,MAAM,EAAE,UADL;AAEHC,cAAAA,OAAO,EAAEvB,MAAM,CAAC,CAACwB,QAAD,EAAWC,KAAX,KAAqB;AAAE,uBAAO;AAAEC,kBAAAA,SAAS,EAAED,KAAK,CAACE;AAAnB,iBAAP;AAAmC,eAA3D;AAFZ;AAFP;AADF,SADF;AAUJC,QAAAA,WAAW,EAAE;AACTX,UAAAA,OAAO,EAAE,UADA;AAETY,UAAAA,KAAK,EAAE,UAFE;AAGTC,UAAAA,IAAI,EAAE,SAHG;AAITX,UAAAA,EAAE,EAAE;AACAY,YAAAA,SAAS,EAAE;AACPR,cAAAA,OAAO,EAAE,CAAC,cAAD,EACLvB,MAAM,CAAC,CAACwB,QAAD,EAAWC,KAAX,KAAqB;AAAE,uBAAO;AAAEO,kBAAAA,SAAS,EAAEP,KAAK,CAACE;AAAnB,iBAAP;AAAmC,eAA3D,CADD,CADF;AAGPL,cAAAA,MAAM,EAAE;AAHD,aADX;AAMAW,YAAAA,UAAU,EAAE,MANZ;AAOAC,YAAAA,QAAQ,EAAE,MAPV;AAQAC,YAAAA,QAAQ,EAAE,MARV;AASAC,YAAAA,QAAQ,EAAE,MATV;AAUAC,YAAAA,QAAQ,EAAE;AAVV,WAJK;AAgBTvB,UAAAA,MAAM,EAAE;AACJwB,YAAAA,QAAQ,EAAE,EADN;AAEJC,YAAAA,KAAK,EAAE;AACHV,cAAAA,KAAK,EAAE5B,IAAI,CAAC,YAAD;AADR;AAFH;AAhBC,SAVT;AAiCJuC,QAAAA,QAAQ,EAAE;AACNX,UAAAA,KAAK,EAAE,UADD;AAENV,UAAAA,EAAE,EAAE;AACAsB,YAAAA,SAAS,EAAE;AADX;AAFE;AAjCN;AAFJ;AAJJ;AAHuC,CAA5B,EAoDnB;AACIlB,EAAAA,OAAO,EAAE;AACLmB,IAAAA,YAAY,EAAGC,OAAD,IAAyB;AACnC;AACAC,MAAAA,OAAO,CAACC,GAAR,CAAY,aAAaF,OAAO,CAACX,SAAjC;AACH,KAJI;AAKLc,IAAAA,IAAI,EAAE,MAAM;AACRF,MAAAA,OAAO,CAACC,GAAR,CAAY,MAAZ;AACH,KAPI;AAQLE,IAAAA,SAAS,EAAGJ,OAAD,IAAyB;AAChC;AACAC,MAAAA,OAAO,CAACC,GAAR,CAAY,oBAAoBF,OAAO,CAACK,OAAR,CAAgBC,MAAhB,CAAuBC,IAAvD;AACH;AAXI;AADb,CApDmB,CAAvB;;AAyEA,MAAMC,cAAc,GAAIC,KAAD,IAA+B;AAClD,UAAQ,IAAR;AACI,SAAKA,KAAK,CAACC,KAAN,CAAYC,OAAZ,CAAoB;AAAEtC,MAAAA,MAAM,EAAE;AAAV,KAApB,CAAL;AACI,0BACI;AAAA,oDAAqB;AAAQ,UAAA,IAAI,EAAC,QAAb;AAAsB,UAAA,SAAS,EAAC,eAAhC;AACjB,UAAA,KAAK,EAAE;AAAEuC,YAAAA,SAAS,EAAE;AAAb;AADU,WAC+BH,KAD/B;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,gBAArB,eAIA;AAAG,UAAA,KAAK,EAAE;AAACI,YAAAA,KAAK,EAAC;AAAP,WAAV;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,gBAJA,eAKA;AAAG,UAAA,IAAI,EAAC;AAAR;AAAA;AAAA;AAAA;AAAA,gBALA;AAAA;AAAA;AAAA;AAAA;AAAA,cADJ;;AAUJ,SAAKJ,KAAK,CAACC,KAAN,CAAYC,OAAZ,CAAoB;AAAEtC,MAAAA,MAAM,EAAE;AAAV,KAApB,CAAL;AACI,0BACI;AAAK,QAAA,SAAS,EAAC,sBAAf;AAAA,+BAEA;AAAQ,UAAA,IAAI,EAAC,QAAb;AAAuB,UAAA,SAAS,EAAC,eAAjC;AACI,UAAA,KAAK,EAAE;AAAEuC,YAAAA,SAAS,EAAE;AAAb;AADX,WACuDH,KADvD;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAFA;AAAA;AAAA;AAAA;AAAA,cADJ;;AASJ;AACI,0BACI;AAAQ,QAAA,IAAI,EAAC,QAAb;AAAsB,QAAA,SAAS,EAAC;AAAhC,SAAoDA,KAApD;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,cADJ;AAvBR;AA6BH,CA9BD;;KAAMD,c;;AAgCN,SAASM,GAAT,GAAe;AAAA;;AAAA,8BACyBjD,kBAAkB,CAAC;AACnDkD,IAAAA,KAAK,EAAE,MAAM;AACTzD,MAAAA,IAAI,CAAC,WAAD,CAAJ;AACH;AAHkD,GAAD,CAD3C;AAAA,QACH0D,KADG,uBACHA,KADG;AAAA,QACIC,MADJ,uBACIA,MADJ;AAAA,QACYpB,QADZ,uBACYA,QADZ,EAQX;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACH;AACG;AACA;AACA;AACA;;;AAjDW,gCAmD2E9B,oBAAoB,CAAC,EAAD,CAnD/F;AAAA,QAmDHmD,UAnDG,yBAmDHA,UAnDG;AAAA,QAmDSC,iBAnDT,yBAmDSA,iBAnDT;AAAA,QAmD4BC,eAnD5B,yBAmD4BA,eAnD5B;AAAA,QAmD6CC,eAnD7C,yBAmD6CA,eAnD7C;AAAA,QAmD8DC,SAnD9D,yBAmD8DA,SAnD9D,EAuDX;AACA;AACA;AACA;AACA;AACA;;;AAEApE,EAAAA,SAAS,CAAC,MAAM;AACZ;AACAY,IAAAA,iBAAiB,CAACyD,cAAlB,CAAiC;AAACC,MAAAA,UAAU,EAAE,KAAb;AAAoBC,MAAAA,QAAQ,EAAE;AAA9B,KAAjC;AACAxB,IAAAA,OAAO,CAACC,GAAR,CAAY,mBAAZ;;AACAwB,IAAAA,QAAQ,EAAEpE,IAAI,CAAC;AAAEY,MAAAA,IAAI,EAAE,WAAR;AAAqBc,MAAAA,KAAK,EAAEoC;AAA5B,KAAD,CAAJ;;AACVC,IAAAA,eAAe;AAClB,GANQ,EAMN,CAACF,iBAAD,EAAoBC,eAApB,CANM,CAAT;;AA9DW,sBAsEsB7D,UAAU,CAACS,OAAD,EAAU;AACjD2D,IAAAA,QAAQ,EAAE,IADuC;AAEjDF,IAAAA,QAAQ,EAAE,OAFuC;AAGjD7C,IAAAA,OAAO,EAAE;AACLgD,MAAAA,QAAQ,EAAEpE,QAAQ,CAAC,MAAM;AACrBiE,QAAAA,QAAQ,EAAE,QADW,CAErB;;;AAEAxB,QAAAA,OAAO,CAACC,GAAR,CAAY,gBAAZ;AACH,OALiB,CADb;AAOL2B,MAAAA,OAAO,EAAErE,QAAQ,CAAC,MAAM;AACpByC,QAAAA,OAAO,CAACC,GAAR,CAAY,sBAAZ;AACA4B,QAAAA,IAAI;AACP,OAHgB,CAPZ;AAWLC,MAAAA,YAAY,EAAEvE,QAAQ,CAAEwC,OAAD,IAAa;AAChCC,QAAAA,OAAO,CAACC,GAAR,CAAY,eAAZ;AACA8B,QAAAA,QAAQ,CAACC,IAAT,CAAcC,KAAd,CAAoBC,UAApB,GAAiCnC,OAAO,CAACX,SAAzC;AACH,OAHqB,CAXjB;AAeL+C,MAAAA,QAAQ,EAAE5E,QAAQ,CAAC,CAACwC,OAAD,EAAUqC,MAAV,KAAqB;AACpCpC,QAAAA,OAAO,CAACC,GAAR,CAAY,aAAZ;AACAc,QAAAA,KAAK,CAAC;AAAES,UAAAA,QAAQ,EAAE,OAAZ;AACFa,UAAAA,IAAI,EAAEtC,OAAO,CAACjB;AADZ,SAAD,CAAL;AAEH,OAJiB,CAfb;AAoBLwD,MAAAA,SAAS,EAAE/E,QAAQ,CAAC,CAACwC,OAAD,EAAUqC,MAAV,KAAqB;AACrCpC,QAAAA,OAAO,CAACC,GAAR,CAAY,aAAZ;AACAe,QAAAA,MAAM;AACT,OAHkB;AAInB;AACZ;AACA;AACA;;AA3BiB;AAHwC,GAAV,CAtEhC;AAAA;AAAA,QAsEJuB,OAtEI;AAAA,QAsEKlF,IAtEL;AAAA,QAsEWmF,OAtEX;AAuGf;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;AACI,sBACI;AAAK,IAAA,SAAS,EAAC,KAAf;AAAA,2BACI,QAAC,cAAD;AAAgB,MAAA,KAAK,EAAED,OAAvB;AAAgC,MAAA,OAAO,EAAE,MAAMlF,IAAI,CAAC,OAAD;AAAnD;AAAA;AAAA;AAAA;AAAA;AADJ;AAAA;AAAA;AAAA;AAAA,UADJ;AAKH;;GAxJQwD,G;UAC+BjD,kB,EAkDkDE,oB,EAmBrDR,U;;;MAtE5BuD,G;AAwJR;AAID;AACA;;AACA,MAAM4B,QAAQ,GAAG,sCAAjB;AACA,MAAMC,OAAO,GAAG,oDAAhB;;AACA,MAAMC,UAAU,GAAIN,IAAD,IACfO,KAAK,CAAC,IAAIC,OAAJ,CAAYJ,QAAQ,GAAGC,OAAvB,EAAgC;AAClCI,EAAAA,MAAM,EAAE,MAD0B;AAElCC,EAAAA,OAAO,EAAE;AAAE,cAAU;AAAZ,GAFyB;AAES;AAC3Cf,EAAAA,IAAI,yBAAeK,IAAf;AAH8B,CAAhC,CAAD,CAAL,CAKKW,IALL,CAKUC,IAAI,IAAIA,IAAI,CAACC,IAAL,EALlB,CADJ;;AAQA,MAAMC,WAAW,GAAGpB,QAAQ,CAACqB,cAAT,CAAwB,MAAxB,CAApB;AACAlG,QAAQ,CAACmG,MAAT,eACI,QAAC,GAAD;AAAA;AAAA;AAAA;AAAA,QADJ,EAEIF,WAFJ","sourcesContent":["import \"./styles.scss\";\r\nimport * as React from \"react\";\r\nimport {useEffect} from 'react'\r\nimport * as ReactDOM from \"react-dom\";\r\nimport { Machine, assign, send, State } from \"xstate\";\r\n\r\nimport { useMachine, asEffect } from \"@xstate/react\";\r\nimport { inspect } from \"@xstate/inspect\";\r\nimport { dmMachine } from \"./dmAppointmentLab4\";\r\n\r\n\r\ninspect({\r\n    url: \"https://statecharts.io/inspect\",\r\n    iframe: false\r\n});\r\n\r\nimport { useSpeechSynthesis } from 'react-speech-kit';\r\nimport  SpeechRecognition, {useSpeechRecognition}  from 'react-speech-recognition'\r\n\r\n\r\nconst machine = Machine<SDSContext, any, SDSEvent>({\r\n    id: 'root',\r\n    type: 'parallel',\r\n    states: {\r\n        dm: {\r\n            ...dmMachine\r\n        },\r\n        asrtts: {\r\n            initial: 'idle',\r\n            states: {\r\n                idle: {\r\n                    on: {\r\n                        LISTEN: 'recognising',\r\n                        SPEAK: {\r\n                            target: 'speaking',\r\n                            actions: assign((_context, event) => { return { ttsAgenda: event.value } })\r\n                        }\r\n                    }\r\n                },\r\n                recognising: {\r\n                    initial: 'progress',\r\n                    entry: 'recStart',\r\n                    exit: 'recStop',\r\n                    on: {\r\n                        ASRRESULT: {\r\n                            actions: ['recLogResult',\r\n                                assign((_context, event) => { return { recResult: event.value } })],\r\n                            target: '.match'\r\n                        },\r\n                        RECOGNISED: 'idle',\r\n                        TIMEOUT1: 'idle',\r\n                        TIMEOUT2: 'idle',\r\n                        TIMEOUT3: 'idle',\r\n                        TIMEOUT4: 'idle', \r\n                    },\r\n                    states: {\r\n                        progress: {},\r\n                        match: {\r\n                            entry: send('RECOGNISED'),\r\n                        },\r\n                    }\r\n                },\r\n                speaking: {\r\n                    entry: 'ttsStart',\r\n                    on: {\r\n                        ENDSPEECH: 'idle',\r\n                    }\r\n                }\r\n            }\r\n        }\r\n    },\r\n},\r\n    {\r\n        actions: {\r\n            recLogResult: (context: SDSContext) => {\r\n                /* context.recResult = event.recResult; */\r\n                console.log('<< ASR: ' + context.recResult);\r\n            },\r\n            test: () => {\r\n                console.log('test')\r\n            },\r\n            logIntent: (context: SDSContext) => {\r\n                /* context.nluData = event.data */\r\n                console.log('<< NLU intent: ' + context.nluData.intent.name)\r\n            }\r\n        },\r\n    });\r\n\r\n\r\n\r\ninterface Props extends React.HTMLAttributes<HTMLElement> {\r\n    state: State<SDSContext, any, any, any>;\r\n}\r\nconst ReactiveButton = (props: Props): JSX.Element => {\r\n    switch (true) {\r\n        case props.state.matches({ asrtts: 'recognising' }):\r\n            return (\r\n                <div>                <button type=\"button\" className=\"glow-on-hover\"\r\n                    style={{ animation: \"glowing 20s linear\" }} {...props}>\r\n                    Listening...\r\n                </button>\r\n                <p style={{color:\"yellow\"}}>aldskhg;lsag;lksadf;lksadlkfha</p>\r\n                <a href=\"\"></a>\r\n                </div>\r\n                \r\n            );\r\n        case props.state.matches({ asrtts: 'speaking' }):\r\n            return (\r\n                <div className=\"style_of_new_element\">\r\n\r\n                <button type=\"button\"  className=\"glow-on-hover\"\r\n                    style={{ animation: \"bordering 1s infinite\" }} {...props}>\r\n                    Speaking...\r\n                </button>\r\n                </div>\r\n            );\r\n        default:\r\n            return (\r\n                <button type=\"button\" className=\"glow-on-hover\" {...props}>\r\n                    Click to start\r\n                </button >\r\n            );\r\n    }\r\n}\r\n\r\nfunction App() {\r\n    const { speak, cancel, speaking } = useSpeechSynthesis({\r\n        onEnd: () => {\r\n            send('ENDSPEECH');\r\n        },\r\n    });\r\n\r\n    \r\n    // const { listen, listening, stop } = useSpeechRecognition({\r\n\r\n    //     onResult: (result: any) => {\r\n    //         send({ type: \"ASRRESULT\", value: result });\r\n    //     },\r\n    // });\r\n    // const [current, send, service] = useMachine(machine, {\r\n    //     devTools: true,\r\n    //     language: \"sv-SE\",\r\n    //     actions: {\r\n    //         recStart: asEffect(() => {\r\n    //             language: \"sv-SE\"\r\n    //             console.log(\"I'm listening.\");\r\n    //             listen({\r\n    //                 interimResults: false,\r\n    //                 continuous: true,\r\n    //                 language: \"sv-SE\"\r\n    //             });\r\n    //         }),\r\n    //         recStop: asEffect(() => {\r\n    //             console.log('Recognition stopped.');\r\n    //             stop()\r\n    //         }),\r\n    //         changeColour: asEffect((context) => {\r\n    //             console.log('Repainting...');\r\n    //             document.body.style.background = context.recResult;\r\n    //         }),\r\n    //         ttsStart: asEffect((context, effect) => {\r\n    //             console.log('Speaking...');\r\n    //             speak({ language: \"sv-SE\",\r\n    //                 text: context.ttsAgenda })\r\n    //         }),\r\n    //         ttsCancel: asEffect((context, effect) => {\r\n    //             console.log('TTS STOP...');\r\n    //             cancel()\r\n    //         })\r\n    //         /speak: asEffect((context) => {\r\n\t//      * console.log('Speaking...');\r\n    //          *     speak({text: context.ttsAgenda })\r\n    //          * } \r\n    //     }\r\n    // });\r\n\r\n    const { transcript, interimTranscript, finalTranscript, resetTranscript, listening} = useSpeechRecognition({\r\n        \r\n    });\r\n\r\n    // const listenContinuously = () => {\r\n    //     SpeechRecognition.startListening({\r\n    //       continuous: true,\r\n    //       language: 'en-GB',\r\n    //     });\r\n    //   };\r\n\r\n    useEffect(() => {\r\n        // const { transcript, resetTranscript } = useSpeechRecognition({});\r\n        SpeechRecognition.startListening({continuous: false, language: \"sv-SE\"});  \r\n        console.log('In startListening')\r\n        onResult: send({ type: \"ASRRESULT\", value: finalTranscript });\r\n        resetTranscript()\r\n    }, [interimTranscript, finalTranscript]);\r\n\r\n    const [current, send, service] = useMachine(machine, {\r\n        devTools: true,\r\n        language: \"sv-SE\",\r\n        actions: {\r\n            recStart: asEffect(() => {\r\n                language: \"sv-SE\"\r\n                //\r\n\r\n                console.log(\"I'm listening.\");\r\n            }),\r\n            recStop: asEffect(() => {\r\n                console.log('Recognition stopped.');\r\n                stop()\r\n            }),\r\n            changeColour: asEffect((context) => {\r\n                console.log('Repainting...');\r\n                document.body.style.background = context.recResult;\r\n            }),\r\n            ttsStart: asEffect((context, effect) => {\r\n                console.log('Speaking...');\r\n                speak({ language: \"sv-SE\",\r\n                    text: context.ttsAgenda })\r\n            }),\r\n            ttsCancel: asEffect((context, effect) => {\r\n                console.log('TTS STOP...');\r\n                cancel()\r\n            })\r\n            /* speak: asEffect((context) => {\r\n\t     * console.log('Speaking...');\r\n             *     speak({text: context.ttsAgenda })\r\n             * } */\r\n        }\r\n    });\r\n/*\r\n    const { listen, listening, stop } = useSpeechRecognition({\r\n\r\n        onResult: (result: any) => {\r\n            send({ type: \"ASRRESULT\", value: result });\r\n        },\r\n    });\r\n    const [current, send, service] = useMachine(machine, {\r\n        devTools: true,\r\n        language: \"sv-SE\",\r\n        actions: {\r\n            recStart: asEffect(() => {\r\n                language: \"sv-SE\"\r\n                console.log(\"I'm listening.\");\r\n                listen({\r\n                    interimResults: false,\r\n                    continuous: true,\r\n                    language: \"sv-SE\"\r\n                });\r\n            }),\r\n            recStop: asEffect(() => {\r\n                console.log('Recognition stopped.');\r\n                stop()\r\n            }),\r\n            changeColour: asEffect((context) => {\r\n                console.log('Repainting...');\r\n                document.body.style.background = context.recResult;\r\n            }),\r\n            ttsStart: asEffect((context, effect) => {\r\n                console.log('Speaking...');\r\n                speak({ language: \"sv-SE\",\r\n                    text: context.ttsAgenda })\r\n            }),\r\n            ttsCancel: asEffect((context, effect) => {\r\n                console.log('TTS STOP...');\r\n                cancel()\r\n            })\r\n            /speak: asEffect((context) => {\r\n\t     * console.log('Speaking...');\r\n             *     speak({text: context.ttsAgenda })\r\n             * } \r\n        }\r\n    });\r\n*/\r\n    return (\r\n        <div className=\"App\">\r\n            <ReactiveButton state={current} onClick={() => send('CLICK')} />\r\n        </div>\r\n    )\r\n};\r\n\r\n\r\n\r\n/* RASA API\r\n *  */\r\nconst proxyurl = \"https://cors-anywhere.herokuapp.com/\";\r\nconst rasaurl = 'https://rafalappointment.herokuapp.com/model/parse'\r\nconst nluRequest = (text: string) =>\r\n    fetch(new Request(proxyurl + rasaurl, {\r\n        method: 'POST',\r\n        headers: { 'Origin': 'http://maraev.me' }, // only required with proxy\r\n        body: `{\"text\": \"${text}\"}`\r\n    }))\r\n        .then(data => data.json());\r\n\r\nconst rootElement = document.getElementById(\"root\");\r\nReactDOM.render(\r\n    <App />,\r\n    rootElement);\r\n"]},"metadata":{},"sourceType":"module"}